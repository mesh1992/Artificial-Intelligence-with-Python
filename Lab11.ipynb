{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab11.ipynb",
      "provenance": [],
      "mount_file_id": "1hIvpEsTq6-jdZ-HzJAQRI6otuwhqpDHY",
      "authorship_tag": "ABX9TyNRKqoO02MnXOXA5cn95ZPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mesh1992/Artificial-Intelligence-with-Python/blob/master/Lab11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj_Scps6D7vZ"
      },
      "outputs": [],
      "source": [
        "#1.\tKNN Algorithm\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer \n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.model_selection import train_test_split \n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "print(cancer.DESCR)\n",
        "\n",
        "print(cancer.feature_names)\n",
        "print(cancer.target_names)\n",
        "\n",
        "cancer.data\n",
        "\n",
        "cancer.data.shape\n",
        "\n",
        "\"\"\"\n",
        "import pandas as pd \n",
        "raw_data=pd.read_csv('breast-cancer-wisconsin-data.csv', delimiter=',') \n",
        "raw_data.tail(10)\n",
        "\n",
        "!pip install mglearn\n",
        "import mglearn\n",
        "# mglearn: a library of utility functions the book \"Introduction to Machine Learning with Python\" including scikit-learn functions\n",
        "\t\t\n",
        "mglearn.plots.plot_knn_classification(n_neighbors=3)\n",
        "\"\"\"\t\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "print('Accuracy of KNN n-5, on the training set: {:.3f}'.format(knn.score(X_train, y_train)))\n",
        "print('Accuracy of KNN n-5, on the test set: {:.3f}'.format(knn.score(X_test, y_test)))\n",
        "\n",
        "# Resplit the data, with a different randomization (inspired by Muller & Guido ML book - https://www.amazon.com/dp/1449369413/)\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
        "\n",
        "# Create two lists for training and test accuracies\n",
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "# Define a range of 1 to 10 (included) neighbors to be tested\n",
        "neighbors_settings = range(1,11)\n",
        "\n",
        "# Loop with the KNN through the different number of neighbors to determine the most appropriate (best)\n",
        "for n_neighbors in neighbors_settings:\n",
        "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    clf.fit(X_train, y_train)\n",
        "    training_accuracy.append(clf.score(X_train, y_train))\n",
        "    test_accuracy.append(clf.score(X_test, y_test))\n",
        "\n",
        "# Visualize results - to help with deciding which n_neigbors yields the best results (n_neighbors=6, in this case)\n",
        "plt.plot(neighbors_settings, training_accuracy, label='Accuracy of the training set')\n",
        "plt.plot(neighbors_settings, test_accuracy, label='Accuracy of the test set')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of Neighbors')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2.\tLogistic Regression\n",
        "# Using LogisticRegression on the cancer dataset. Inspired by Muller and Guido ML book: (https://www.amazon.com/dp/1449369413/)\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "print('Accuracy on the training subset: {:.3f}'.format(log_reg.score(X_train, y_train)))\n",
        "print('Accuracy on the test subset: {:.3f}'.format(log_reg.score(X_test, y_test)))\n",
        "\t\n",
        "\t\n",
        "\"\"\"\n",
        "'C':\n",
        "parameter to control the strength of regularization\n",
        "lower C => log_reg adjusts to the majority of data points.\n",
        "higher C => correct classification of each data point.\n",
        "\"\"\"\n",
        "\t\t\n",
        "log_reg100 = LogisticRegression(C=100)\n",
        "log_reg100.fit(X_train, y_train)\n",
        "print('Accuracy on the training subset: {:.3f}'.format(log_reg100.score(X_train, y_train)))\n",
        "print('Accuracy on the test subset: {:.3f}'.format(log_reg100.score(X_test, y_test)))\n",
        "\n",
        "log_reg001 = LogisticRegression(C=0.01)\n",
        "log_reg001.fit(X_train, y_train)\n",
        "print('Accuracy on the training subset: {:.3f}'.format(log_reg001.score(X_train, y_train)))\n",
        "print('Accuracy on the test subset: {:.3f}'.format(log_reg001.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "plt.plot(log_reg.coef_.T, 'o', label='C=1')\n",
        "plt.plot(log_reg100.coef_.T, '^', label='C=100')\n",
        "plt.plot(log_reg001.coef_.T, 'v', label='C=0.01')\n",
        "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
        "plt.hlines(0,0, cancer.data.shape[1])\t# hlines: horizontal line \n",
        "plt.ylim(-5,5)\t\t\t\t# ylim: y limit value\n",
        "plt.xlabel('Coefficient Index')\n",
        "plt.ylabel('Coefficient Magnitude')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "drqBhgZMEwiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3.\tDecision Trees\n",
        "!pip install mglearn\n",
        "\n",
        "import mglearn \n",
        "# credits to Muller and Guido (https://www.amazon.com/dp/1449369413/)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "mglearn.plots.plot_tree_not_monotone()\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
        "tree = DecisionTreeClassifier(random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "print('Accuracy on the training subset: {:.3f}'.format(tree.score(X_train, y_train)))\n",
        "print('Accuracy on the test subset: {:.3f}'.format(tree.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "print('Accuracy on the training subset: {:.3f}'.format(tree.score(X_train, y_train)))\n",
        "print('Accuracy on the test subset: {:.3f}'.format(tree.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(tree, out_file='cancertree.dot', class_names=['malignant', 'benign'], feature_names=cancer.feature_names,impurity=False, filled=True)\n",
        "\t\n",
        "print('Feature importances: {}'.format(tree.feature_importances_))\n",
        "type(tree.feature_importances_)\n",
        "\n",
        "\n",
        "print(cancer.feature_names)\n",
        "\n",
        "\n",
        "n_features = cancer.data.shape[1]\n",
        "plt.barh(range(n_features), tree.feature_importances_, align='center')\n",
        "plt.yticks(np.arange(n_features), cancer.feature_names)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "rIsyrUXhE7oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.\tRandom Forests\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "forest.fit(X_train, y_train)\n",
        "# n_estimatorsï¼šthe number of trees\n",
        "\n",
        "print('Accuracy on the training subset: {:.3f}'.format(forest.score(X_train, y_train)))\n",
        "print('Accuracy on the test subset: {:.3f}'.format(forest.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "n_features = cancer.data.shape[1] \n",
        "plt.barh(range(n_features), forest.feature_importances_, align='center') plt.yticks(np.arange(n_features), cancer.feature_names) \n",
        "plt.xlabel('Feature Importance') \n",
        "plt.ylabel('Feature') \n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Po7HHIHBFDyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s0M6a6cvFOsF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}